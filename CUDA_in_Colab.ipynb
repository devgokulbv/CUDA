{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devgokulbv/CUDA/blob/main/CUDA_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install CUDA C++ plugin for Colab:\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntOgKF_-y0SV",
        "outputId": "90ddba7c-a1f5-4730-de4e-5e7b164c135d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpot9bqey1\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect selected GPU and its NVIDA architecture:\n",
        "import subprocess\n",
        "gpu_info = subprocess.getoutput(\"nvidia-smi --query-gpu=name,compute_cap --format=csv,noheader,nounits\")\n",
        "if \"not found\" in gpu_info.lower(): raise RuntimeError(\"Error: No GPU found. Please select a GPU runtime environment.\")\n",
        "gpu_name, compute_cap = map(str.strip, gpu_info.split(','))\n",
        "gpu_arch = f\"sm_{compute_cap.replace('.', '')}\"\n",
        "\n",
        "print(f\"{'GPU Name':<15}: {gpu_name}\")\n",
        "print(f\"{'Architecture':<15}: {gpu_arch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVqh0baiO15d",
        "outputId": "1476cda7-5689-4113-cf7b-fbe686f45c38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Name       : Tesla T4\n",
            "Architecture   : sm_75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda -c \"--gpu-architecture $gpu_arch\"\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello_kernel() {\n",
        "    int blockId = blockIdx.x;\n",
        "    int threadId = threadIdx.x;\n",
        "    int globalId = threadId + blockId * blockDim.x;\n",
        "\n",
        "    printf(\"Hello from block %d, thread %d (global thread %d)\\n\", blockId, threadId, globalId);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int numBlocks = 2;\n",
        "    int threadsPerBlock = 4;\n",
        "\n",
        "    hello_kernel<<<numBlocks, threadsPerBlock>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HW8N8RXzCTc",
        "outputId": "b7bcabf9-fbad-4bfd-dec6-9121031ecb21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from block 0, thread 0 (global thread 0)\n",
            "Hello from block 0, thread 1 (global thread 1)\n",
            "Hello from block 0, thread 2 (global thread 2)\n",
            "Hello from block 0, thread 3 (global thread 3)\n",
            "Hello from block 1, thread 0 (global thread 4)\n",
            "Hello from block 1, thread 1 (global thread 5)\n",
            "Hello from block 1, thread 2 (global thread 6)\n",
            "Hello from block 1, thread 3 (global thread 7)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda -c \"--gpu-architecture $gpu_arch\"\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#define row 3\n",
        "#define col 3\n",
        "\n",
        "__global__ void kernel(float *c,float *a, float *b, int n)\n",
        "{\n",
        "    int global_id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (global_id < n)\n",
        "    {\n",
        "        c[global_id] = a[global_id] + b[global_id];\n",
        "    }\n",
        "}\n",
        "int main()\n",
        "{\n",
        "    float a[row][col], b[row][col], c[row][col];\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    int size = row * col * sizeof(float);\n",
        "    int num = row * col;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    for (int i = 0; i < row; i++)\n",
        "    {\n",
        "        for (int j = 0; j < col; j++)\n",
        "        {\n",
        "            a[i][j] = rand() % 100;\n",
        "            b[i][j] = rand() % 100;\n",
        "            printf(\"%f \", a[i][j]);\n",
        "\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    for (int i = 0; i < row; i++)\n",
        "    {\n",
        "        for (int j = 0; j < col; j++)\n",
        "        {\n",
        "\n",
        "            printf(\"%f \", b[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    kernel<<<3, 3>>>(d_c, d_a, d_b, num);\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < row; i++)\n",
        "    {\n",
        "        for (int j = 0; j < col; j++)\n",
        "        {\n",
        "            printf(\"%f \", c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc0x6Wv57HeA",
        "outputId": "4789fb22-e908-4b2d-87e8-c2e8ac8e5dcd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83.000000 77.000000 93.000000 \n",
            "86.000000 49.000000 62.000000 \n",
            "90.000000 63.000000 40.000000 \n",
            "\n",
            "86.000000 15.000000 35.000000 \n",
            "92.000000 21.000000 27.000000 \n",
            "59.000000 26.000000 26.000000 \n",
            "\n",
            "169.000000 92.000000 128.000000 \n",
            "178.000000 70.000000 89.000000 \n",
            "149.000000 89.000000 66.000000 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}